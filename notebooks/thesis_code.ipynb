{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Analysis Toolchain\n",
    "\n",
    "This notebook provides modular functions for data processing, vectorization, and model generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import flaml\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess the dataset.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading data from {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_embed(texts: List[str], model_type: str = \"bert-base-uncased\") -> np.ndarray:\n",
    "    \"\"\"Tokenize and embed text using the specified model.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings to embed\n",
    "        model_type: Name of the transformer model to use\n",
    "        \n",
    "    Returns:\n",
    "        Array of embeddings\n",
    "    \"\"\"\n",
    "    logging.info(f\"Tokenizing and embedding using {model_type}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    model = AutoModel.from_pretrained(model_type)\n",
    "    \n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    \n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_automl(X: np.ndarray, y: np.ndarray, task: str = \"classification\", time_budget: int = 60) -> Tuple[Any, Dict]:\n",
    "    \"\"\"Train an AutoML model using FLAML.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Target vector\n",
    "        task: Type of ML task ('classification' or 'regression')\n",
    "        time_budget: Time budget in seconds\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (trained model, metrics)\n",
    "    \"\"\"\n",
    "    logging.info(f\"Training AutoML model for task: {task}\")\n",
    "    automl = flaml.AutoML()\n",
    "    automl.fit(X, y, task=task, time_budget=time_budget)\n",
    "    \n",
    "    metrics = {\n",
    "        \"best_estimator\": str(automl.best_estimator),\n",
    "        \"best_config\": automl.best_config,\n",
    "        \"best_loss\": automl.best_loss,\n",
    "        \"time_to_best\": automl.time_to_best\n",
    "    }\n",
    "    \n",
    "    return automl, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_visualization(model_metrics: Dict, embeddings: np.ndarray) -> Dict:\n",
    "    \"\"\"Prepare visualization data.\n",
    "    \n",
    "    Args:\n",
    "        model_metrics: Dictionary of model metrics\n",
    "        embeddings: Array of embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with chart data\n",
    "    \"\"\"\n",
    "    charts = [\n",
    "        {\n",
    "            \"type\": \"scatter\",\n",
    "            \"data\": {\n",
    "                \"embeddings\": embeddings.tolist()\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"charts\": charts,\n",
    "        \"metrics\": model_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(csv_path: str, model_type: str = \"bert-base-uncased\") -> str:\n",
    "    \"\"\"Main analysis function that will be called by the Rust bridge.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the input CSV file\n",
    "        model_type: Type of transformer model to use\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with analysis results\n",
    "    \"\"\"\n",
    "    # Load and preprocess data\n",
    "    df = load_data(csv_path)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    text_column = df.select_dtypes(include=['object']).columns[0]  # Use first text column\n",
    "    embeddings = tokenize_and_embed(df[text_column].tolist(), model_type)\n",
    "    \n",
    "    # Prepare labels if available\n",
    "    if 'label' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        labels = le.fit_transform(df['label'])\n",
    "        \n",
    "        # Train AutoML model\n",
    "        model, metrics = train_automl(embeddings, labels)\n",
    "    else:\n",
    "        metrics = {}\n",
    "    \n",
    "    # Prepare visualization data\n",
    "    result = prepare_visualization(metrics, embeddings)\n",
    "    \n",
    "    return json.dumps(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
